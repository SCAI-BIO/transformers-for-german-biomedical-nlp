[Data]
whole_data = data/processed/whole_dataset.pt
training_data = data/processed/training_dataset.pt
validation_data = data/processed/validation_dataset.pt
testing_data = data/processed/testing_dataset.pt
label_set = data/processed/label_set.pt

[Model]
name = gottbert-base
model = uklfr/gottbert-base
tokenizer = data/external/gottbert-base
tokenizer_type = pretrained
model_function = RobertaForTokenClassification
tokenizer_function = RobertaTokenizerFast
registered_model = 

[Training]
learning_rate = 2e-05
epochs = 50
early_stopping_patience = 5
early_stopping_threshold = 0.01
metric = eval_macro_f1
greater_is_better = True
trainer_function = Trainer
trainer_module = transformers
train_batch_size = 16
eval_batch_size = 16
warmup_steps = 50

[Logging]
experiment_name = charite_ehr
tracking_uri = http://localhost:45823

[Storage]
results = reports/tables

[Ganbert]
use = False

